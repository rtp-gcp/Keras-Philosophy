{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train, test and validation dataframes\n",
    "\n",
    "## No normalization\n",
    "\n",
    "## Augmentation added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input File Selection and Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file can be varied to point to different files.\n",
    "# However, this model assumes these columns:\n",
    "#  Z (Target) \n",
    "#  X (Feature 1 or X_1)\n",
    "#  Y (Feature 1 or X_2)\n",
    "#  ... (Feature N)\n",
    "#\n",
    "# For this demo, it was three columns where:\n",
    "#    where z = x + y\n",
    "\n",
    "# sample data for easy x+y=z\n",
    "# JUST z=10\n",
    "CSV_FILE_NAME = \"xyz10.csv\"\n",
    "\n",
    "# sample data for easy x+y=z\n",
    "#CSV_FILE_NAME = \"xyz.csv\"\n",
    "\n",
    "os.environ['CSV_FILE_NAME'] = CSV_FILE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory is : /Users/davis/progs/github/Keras-Philosophy/src\n"
     ]
    }
   ],
   "source": [
    "# The current directory will be where this src file is located.\n",
    "# Which is in the src dir of the project\n",
    "dirpath = os.getcwd()\n",
    "print(\"current directory is : \" + dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent directory is : /Users/davis/progs/github/Keras-Philosophy\n"
     ]
    }
   ],
   "source": [
    "root_path = os.path.dirname(dirpath)\n",
    "print(\"parent directory is : \" + root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data direcotry is: /Users/davis/progs/github/Keras-Philosophy/data/\n"
     ]
    }
   ],
   "source": [
    "data_path = root_path + \"/data/\"\n",
    "print(\"data direcotry is: \" + data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log direcotry is: /Users/davis/progs/github/Keras-Philosophy/logs/\n"
     ]
    }
   ],
   "source": [
    "log_path = root_path + \"/logs/\"\n",
    "# logs needs to be used by the shell commands also\n",
    "os.environ['LOG_DIR_NAME'] = log_path\n",
    "\n",
    "print(\"log direcotry is: \" + log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully qualified csv file name:  /Users/davis/progs/github/Keras-Philosophy/data/xyz10.csv\n"
     ]
    }
   ],
   "source": [
    "fqfn = data_path + CSV_FILE_NAME\n",
    "print(\"fully qualified csv file name: \", fqfn)\n",
    "# For debug, save Fully qualifed input file\n",
    "# logs needs to be used by the shell commands also\n",
    "os.environ['CSV_FQFN'] = fqfn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV_FILE_NAME: xyz10.csv\n",
      "CSV_FQFN: /Users/davis/progs/github/Keras-Philosophy/data/xyz10.csv\n",
      "LOG_DIR_NAME: /Users/davis/progs/github/Keras-Philosophy/logs/\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"CSV_FILE_NAME: ${CSV_FILE_NAME}\"\n",
    "echo \"CSV_FQFN: ${CSV_FQFN}\"\n",
    "echo \"LOG_DIR_NAME: ${LOG_DIR_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z,x,y\n",
      "10.0,10.0,0.0\n",
      "10.0,9.0,1.0\n",
      "10.0,8.0,2.0\n",
      "10.0,7.0,3.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      14 /Users/davis/progs/github/Keras-Philosophy/data/xyz10.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# show first five lines\n",
    "head -5 \"${CSV_FQFN}\"\n",
    "# determine how many lines are in the file including the header row\n",
    "wc -l \"${CSV_FQFN}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pandas to read csv into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframe = pd.read_csv(fqfn, \n",
    "                          header=0,\n",
    "                          sep=\",\")\n",
    "\n",
    "dataframe = raw_dataframe.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>z</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      z     x    y\n",
       "0  10.0  10.0  0.0\n",
       "1  10.0   9.0  1.0\n",
       "2  10.0   8.0  2.0\n",
       "3  10.0   7.0  3.0\n",
       "4  10.0   6.0  4.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment the data\n",
    "\n",
    "Increase the size of the existing dataset by creating a new copy.  In the copy add tiny amount to x column and then subtract the same amount to the y column so that the sum remains constant.  Dupe this process 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a routine to augment an existing df\n",
    "def create_aug_df(a_df): \n",
    "\n",
    "    copy_df = a_df.copy()\n",
    "\n",
    "    # drop rows with zero in X\n",
    "    copy_df = copy_df[copy_df.x != 0]\n",
    "\n",
    "    # drop rows with zero in y\n",
    "    copy_df = copy_df[copy_df.y != 0]\n",
    "\n",
    "    # so we don't introduce negative numbers, get the minimum and set that \n",
    "    # as the floor. \n",
    "    min_val = copy_df.min(axis=None)\n",
    "    rnd_val = np.random.rand()\n",
    "    mod_val = np.minimum(min_val, rnd_val)\n",
    "    #print(\"min_value: \",min_val)\n",
    "    #print(\"mod_value: \", mod_val)\n",
    "\n",
    "    # adj columns x and y by mod amount\n",
    "    copy_df['x'] = copy_df['x'] + mod_val\n",
    "    copy_df['y'] = copy_df['y'] - mod_val\n",
    "\n",
    "    return copy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function to create a larger augmented dataframe\n",
    "df_list = []\n",
    "for x in range(0,100):\n",
    "    df_list.append(create_aug_df(dataframe))\n",
    "\n",
    "aug_df = pd.concat(df_list)\n",
    "#print(\"augmented df shape: \", aug_df.shape)\n",
    "#print(\"aug_df head: \")\n",
    "#print(aug_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train, Test and Validation DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we used concat, our index is screwed uup\n",
    "# create a new index and apply it\n",
    "num_rows = aug_df.shape[0]\n",
    "index = pd.Index(range(0,num_rows))\n",
    "aug_df.set_index(index,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (630, 3)\n",
      "test shape:  (135, 3)\n",
      "valid shape:  (135, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# sample 70% of aumented data to the train_df\n",
    "train_df = aug_df.sample(frac=0.7,random_state=3367)\n",
    "# what's leftover will be split into test and train evenly\n",
    "leftover_df = aug_df.drop(train_df.index) \n",
    "# split what's leftover into test and validation                       \n",
    "test_df = leftover_df.sample(frac=0.5, random_state=3367)\n",
    "valid_df = leftover_df.drop(test_df.index)\n",
    "# print sizes as check\n",
    "print(\"train shape: \", train_df.shape)\n",
    "print(\"test shape: \", test_df.shape)\n",
    "print(\"valid shape: \", valid_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write the dataframes to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(data_path + \"/\" + \"train.csv\", encoding='utf-8', index=False)\n",
    "test_df.to_csv(data_path + \"/\" + \"test.csv\", encoding=\"utf-8\", index=False)\n",
    "valid_df.to_csv(data_path + \"/\" + \"valid.csv\", encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>630.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>630.0</td>\n",
       "      <td>5.512188</td>\n",
       "      <td>2.614739</td>\n",
       "      <td>1.021156</td>\n",
       "      <td>3.198320</td>\n",
       "      <td>5.527674</td>\n",
       "      <td>7.839908</td>\n",
       "      <td>9.990275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>630.0</td>\n",
       "      <td>4.487812</td>\n",
       "      <td>2.614739</td>\n",
       "      <td>0.009725</td>\n",
       "      <td>2.160092</td>\n",
       "      <td>4.472326</td>\n",
       "      <td>6.801680</td>\n",
       "      <td>8.978844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count       mean       std        min        25%        50%        75%  \\\n",
       "z  630.0  10.000000  0.000000  10.000000  10.000000  10.000000  10.000000   \n",
       "x  630.0   5.512188  2.614739   1.021156   3.198320   5.527674   7.839908   \n",
       "y  630.0   4.487812  2.614739   0.009725   2.160092   4.472326   6.801680   \n",
       "\n",
       "         max  \n",
       "z  10.000000  \n",
       "x   9.990275  \n",
       "y   8.978844  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# typically only use the train dataframe to normalize the data\n",
    "train_stats_df = train_df\n",
    "train_stats = train_stats_df.describe().transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
